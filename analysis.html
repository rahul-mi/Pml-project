I first opened the training data and glanced the columns. I found that there are 160 columns. Many columns are with empty data or 
non-numerical data or having #DIV/0!. I removed these by choosing columns without any NA values and columns with non-zero variance. 
This reduced the number of columns to 53. Now I used the prediction model of random forests and found the accuracy of the model > 99% 
on the validation set. And therefore chose this to classify the 20 data points in the testing set as well.

Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 1674    6    0    0    0
         B    0 1130    7    0    0
         C    0    3 1019   11    2
         D    0    0    0  953    5
         E    0    0    0    0 1075

Overall Statistics
                                         
               Accuracy : 0.9942         
                 95% CI : (0.9919, 0.996)
    No Information Rate : 0.2845         
    P-Value [Acc > NIR] : < 2.2e-16      
                                         
                  Kappa : 0.9927         
 Mcnemar's Test P-Value : NA             

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            1.0000   0.9921   0.9932   0.9886   0.9935
Specificity            0.9986   0.9985   0.9967   0.9990   1.0000
Pos Pred Value         0.9964   0.9938   0.9845   0.9948   1.0000
Neg Pred Value         1.0000   0.9981   0.9986   0.9978   0.9985
Prevalence             0.2845   0.1935   0.1743   0.1638   0.1839
Detection Rate         0.2845   0.1920   0.1732   0.1619   0.1827
Detection Prevalence   0.2855   0.1932   0.1759   0.1628   0.1827
Balanced Accuracy      0.9993   0.9953   0.9949   0.9938   0.9968
